{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kLSxXn-I3euv",
    "outputId": "1492326e-9393-47a9-da2e-00443612449a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import os\n",
    "import gc\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import TimeSeriesSplit, GroupKFold, StratifiedGroupKFold\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "o0CkODSm4uCw"
   },
   "outputs": [],
   "source": [
    "class Data_Pipeline:\n",
    "    def data_dtypes_adj(df): # set_table_dtypes\n",
    "        for col in df.columns:\n",
    "            if col in [\"case_id\", \"WEEK_NUM\", \"num_group1\", \"num_group2\"]:\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Int64))\n",
    "            elif col in [\"date_decision\"]:\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Date))\n",
    "            elif col[-1] in (\"P\", \"A\"):\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Float64))\n",
    "            elif col[-1] in (\"M\",):\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Utf8))\n",
    "            elif col[-1] in (\"D\",):\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Date))\n",
    "                \n",
    "        return df\n",
    "\n",
    "    def date_adj(df): #  handle_dates\n",
    "        for col in df.columns:\n",
    "            if col[-1] in (\"D\"):\n",
    "                df = df.with_columns(pl.col(col) - pl.col(\"date_decision\"))\n",
    "                df = df.with_columns(pl.col(col).dt.total_days())\n",
    "\n",
    "        df = df.drop(\"date_decision\", \"MONTH\")\n",
    "\n",
    "        return df\n",
    "\n",
    "    def col_filter(df): # filter_cols\n",
    "        for col in df.columns:\n",
    "            if col not in [\"target\", \"case_id\", \"WEEK_NUM\"]:\n",
    "                if df[col].dtype != pl.String:\n",
    "                    isnull = df[col].is_null().mean()\n",
    "                    if isnull > 0.90:\n",
    "                        df = df.drop(col)\n",
    "                else:\n",
    "                    freq = df[col].n_unique()\n",
    "                    if (freq == 1) | (freq > 200):\n",
    "                        df = df.drop(col)\n",
    "        return df\n",
    "    \n",
    "    def reduce_mem_usage(df, int_cast=True, obj_to_category=False, subset=None):\n",
    "        start_mem = df.memory_usage().sum() / 1024 ** 2;\n",
    "        gc.collect()\n",
    "        print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "\n",
    "        cols = subset if subset is not None else df.columns.tolist()\n",
    "\n",
    "        for col in cols:\n",
    "            col_type = df[col].dtype\n",
    "\n",
    "            if col_type != object and col_type.name != 'category' and 'datetime' not in col_type.name:\n",
    "                df[col] = df[col].fillna(-888)\n",
    "                c_min = df[col].min()\n",
    "                c_max = df[col].max()\n",
    "                treat_as_int = True\n",
    "                if treat_as_int:\n",
    "                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                        df[col] = df[col].astype(np.int8)\n",
    "                    elif c_min > np.iinfo(np.uint8).min and c_max < np.iinfo(np.uint8).max:\n",
    "                        df[col] = df[col].astype(np.uint8)\n",
    "                    elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                        df[col] = df[col].astype(np.int16)\n",
    "                    elif c_min > np.iinfo(np.uint16).min and c_max < np.iinfo(np.uint16).max:\n",
    "                        df[col] = df[col].astype(np.uint16)\n",
    "                    elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                        df[col] = df[col].astype(np.int32)\n",
    "                    elif c_min > np.iinfo(np.uint32).min and c_max < np.iinfo(np.uint32).max:\n",
    "                        df[col] = df[col].astype(np.uint32)\n",
    "                    elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                        df[col] = df[col].astype(np.int64)\n",
    "                    elif c_min > np.iinfo(np.uint64).min and c_max < np.iinfo(np.uint64).max:\n",
    "                        df[col] = df[col].astype(np.uint64)\n",
    "                else:\n",
    "                    if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                        df[col] = df[col].astype(np.float16)\n",
    "                    elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                        df[col] = df[col].astype(np.float32)\n",
    "                    else:\n",
    "                        df[col] = df[col].astype(np.float64)\n",
    "            elif 'datetime' not in col_type.name and obj_to_category:\n",
    "                df[col] = df[col].fillna('Mis')\n",
    "                df[col] = df[col].astype('category')\n",
    "        gc.collect()\n",
    "        end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "        print('Memory usage after optimization is: {:.3f} MB'.format(end_mem))\n",
    "        print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ly4jd5ja4x8-"
   },
   "outputs": [],
   "source": [
    "class Aggregator:\n",
    "    def num_expr(df):\n",
    "        cols = [col for col in df.columns if col[-1] in (\"P\", \"A\")]\n",
    "        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n",
    "        expr_min = [pl.min(col).alias(f\"min_{col}\") for col in cols]\n",
    "        expr_mean = [pl.mean(col).alias(f\"mean_{col}\") for col in cols]\n",
    "        return expr_max\n",
    "\n",
    "    def date_expr(df):\n",
    "        cols = [col for col in df.columns if col[-1] in (\"D\",)]\n",
    "        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n",
    "        expr_min = [pl.min(col).alias(f\"min_{col}\") for col in cols]\n",
    "        expr_mean = [pl.mean(col).alias(f\"mean_{col}\") for col in cols]\n",
    "        return expr_max\n",
    "\n",
    "    def str_expr(df):\n",
    "        cols = [col for col in df.columns if col[-1] in (\"M\",)]\n",
    "        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n",
    "        expr_min = [pl.min(col).alias(f\"min_{col}\") for col in cols]\n",
    "        expr_mean = [pl.mean(col).alias(f\"mean_{col}\") for col in cols]\n",
    "        return expr_max\n",
    "\n",
    "    def other_expr(df):\n",
    "        cols = [col for col in df.columns if col[-1] in (\"T\", \"L\")]\n",
    "        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n",
    "        expr_min = [pl.min(col).alias(f\"min_{col}\") for col in cols]\n",
    "        expr_mean = [pl.mean(col).alias(f\"mean_{col}\") for col in cols]\n",
    "        return expr_max\n",
    "\n",
    "    def count_expr(df):\n",
    "        cols = [col for col in df.columns if \"num_group\" in col]\n",
    "        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n",
    "        expr_min = [pl.min(col).alias(f\"min_{col}\") for col in cols]\n",
    "        expr_mean = [pl.mean(col).alias(f\"mean_{col}\") for col in cols]\n",
    "        return expr_max\n",
    "\n",
    "    def get_exprs(df):\n",
    "        exprs = Aggregator.num_expr(df) + \\\n",
    "                Aggregator.date_expr(df) + \\\n",
    "                Aggregator.str_expr(df) + \\\n",
    "                Aggregator.other_expr(df) + \\\n",
    "                Aggregator.count_expr(df)\n",
    "\n",
    "        return exprs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "XxCti04I5Fqb"
   },
   "outputs": [],
   "source": [
    "def feature_eng(df_base, depth_0, depth_1, depth_2):\n",
    "    df_base = (\n",
    "        df_base\n",
    "        .with_columns(\n",
    "            month_decision = pl.col(\"date_decision\").dt.month(),\n",
    "            weekday_decision = pl.col(\"date_decision\").dt.weekday(),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    for i, df in enumerate(depth_0 + depth_1 + depth_2):\n",
    "        df_base = df_base.join(df, how=\"left\", on=\"case_id\", suffix=f\"_{i}\")\n",
    "\n",
    "    df_base = df_base.pipe(Data_Pipeline.date_adj)\n",
    "\n",
    "    return df_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "_ncq8gJk5Gk7"
   },
   "outputs": [],
   "source": [
    "def to_pandas(df_data, cat_cols=None):\n",
    "    df_data = df_data.to_pandas()\n",
    "\n",
    "    if cat_cols is None:\n",
    "        cat_cols = list(df_data.select_dtypes(\"object\").columns)\n",
    "\n",
    "    df_data[cat_cols] = df_data[cat_cols].astype(\"category\")\n",
    "\n",
    "    return df_data, cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "x-Amzrcz42Xq"
   },
   "outputs": [],
   "source": [
    "def read_file(path, depth=None):\n",
    "    df = pd.read_parquet(path)\n",
    "    df = df.pipe(Data_Pipeline.reduce_mem_usage)\n",
    "    df = pl.from_pandas(df)\n",
    "    df = df.pipe(Data_Pipeline.data_dtypes_adj)\n",
    "    if depth in [1, 2]:\n",
    "        df = df.group_by(\"case_id\").agg(Aggregator.get_exprs(df))\n",
    "\n",
    "    return df\n",
    "\n",
    "def read_files(regex_path, depth=None):\n",
    "    chunks = []\n",
    "    for path in glob(str(regex_path)):\n",
    "        chunks.append(pl.from_pandas(pd.read_parquet(path).pipe(Data_Pipeline.reduce_mem_usage)).pipe(Data_Pipeline.data_dtypes_adj))\n",
    "\n",
    "    df = pl.concat(chunks, how=\"vertical_relaxed\")\n",
    "    if depth in [1, 2]:\n",
    "        df = df.group_by(\"case_id\").agg(Aggregator.get_exprs(df))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "fFuqtjwPN1u4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 58.24 MB\n",
      "Memory usage after optimization is: 26.207 MB\n",
      "Decreased by 55.0%\n",
      "Memory usage of dataframe is 606.73 MB\n",
      "Memory usage after optimization is: 306.227 MB\n",
      "Decreased by 49.5%\n",
      "Memory usage of dataframe is 1279.85 MB\n",
      "Memory usage after optimization is: 572.440 MB\n",
      "Decreased by 55.3%\n",
      "Memory usage of dataframe is 666.73 MB\n",
      "Memory usage after optimization is: 300.703 MB\n",
      "Decreased by 54.9%\n",
      "Memory usage of dataframe is 1216.09 MB\n",
      "Memory usage after optimization is: 863.867 MB\n",
      "Decreased by 29.0%\n",
      "Memory usage of dataframe is 825.27 MB\n",
      "Memory usage after optimization is: 586.245 MB\n",
      "Decreased by 29.0%\n",
      "Memory usage of dataframe is 124.96 MB\n",
      "Memory usage after optimization is: 78.101 MB\n",
      "Decreased by 37.5%\n",
      "Memory usage of dataframe is 42.26 MB\n",
      "Memory usage after optimization is: 26.415 MB\n",
      "Decreased by 37.5%\n",
      "Memory usage of dataframe is 127.56 MB\n",
      "Memory usage after optimization is: 79.723 MB\n",
      "Decreased by 37.5%\n",
      "Memory usage of dataframe is 29.45 MB\n",
      "Memory usage after optimization is: 17.263 MB\n",
      "Decreased by 41.4%\n",
      "Memory usage of dataframe is 2476.11 MB\n",
      "Memory usage after optimization is: 1402.607 MB\n",
      "Decreased by 43.4%\n",
      "Memory usage of dataframe is 3621.87 MB\n",
      "Memory usage after optimization is: 2063.092 MB\n",
      "Decreased by 43.0%\n",
      "Memory usage of dataframe is 1253.25 MB\n",
      "Memory usage after optimization is: 717.845 MB\n",
      "Decreased by 42.7%\n",
      "Memory usage of dataframe is 2256.48 MB\n",
      "Memory usage after optimization is: 1306.758 MB\n",
      "Decreased by 42.1%\n",
      "Memory usage of dataframe is 2.73 MB\n",
      "Memory usage after optimization is: 1.219 MB\n",
      "Decreased by 55.4%\n",
      "Memory usage of dataframe is 839.52 MB\n",
      "Memory usage after optimization is: 728.908 MB\n",
      "Decreased by 13.2%\n",
      "Memory usage of dataframe is 5.53 MB\n",
      "Memory usage after optimization is: 3.459 MB\n",
      "Decreased by 37.5%\n",
      "Memory usage of dataframe is 7.20 MB\n",
      "Memory usage after optimization is: 3.750 MB\n",
      "Decreased by 47.9%\n",
      "Memory usage of dataframe is 58.90 MB\n",
      "Memory usage after optimization is: 26.997 MB\n",
      "Decreased by 54.2%\n",
      "Memory usage of dataframe is 137.92 MB\n",
      "Memory usage after optimization is: 109.710 MB\n",
      "Decreased by 20.5%\n",
      "Memory usage of dataframe is 3917.61 MB\n",
      "Memory usage after optimization is: 2396.959 MB\n",
      "Decreased by 38.8%\n",
      "Memory usage of dataframe is 4791.42 MB\n",
      "Memory usage after optimization is: 2931.595 MB\n",
      "Decreased by 38.8%\n",
      "Memory usage of dataframe is 635.80 MB\n",
      "Memory usage after optimization is: 384.825 MB\n",
      "Decreased by 39.5%\n",
      "Memory usage of dataframe is 1167.78 MB\n",
      "Memory usage after optimization is: 683.768 MB\n",
      "Decreased by 41.4%\n",
      "Memory usage of dataframe is 3698.08 MB\n",
      "Memory usage after optimization is: 2262.644 MB\n",
      "Decreased by 38.8%\n",
      "Memory usage of dataframe is 3850.66 MB\n",
      "Memory usage after optimization is: 2355.998 MB\n",
      "Decreased by 38.8%\n",
      "Memory usage of dataframe is 2593.82 MB\n",
      "Memory usage after optimization is: 1587.008 MB\n",
      "Decreased by 38.8%\n",
      "Memory usage of dataframe is 2714.09 MB\n",
      "Memory usage after optimization is: 1660.595 MB\n",
      "Decreased by 38.8%\n",
      "Memory usage of dataframe is 767.70 MB\n",
      "Memory usage after optimization is: 414.157 MB\n",
      "Decreased by 46.1%\n",
      "Memory usage of dataframe is 1139.64 MB\n",
      "Memory usage after optimization is: 682.282 MB\n",
      "Decreased by 40.1%\n",
      "Memory usage of dataframe is 2018.85 MB\n",
      "Memory usage after optimization is: 1235.216 MB\n",
      "Decreased by 38.8%\n",
      "Memory usage of dataframe is 644.32 MB\n",
      "Memory usage after optimization is: 402.703 MB\n",
      "Decreased by 37.5%\n",
      "Memory usage of dataframe is 0.00 MB\n",
      "Memory usage after optimization is: 0.000 MB\n",
      "Decreased by 37.9%\n",
      "Memory usage of dataframe is 0.00 MB\n",
      "Memory usage after optimization is: 0.002 MB\n",
      "Decreased by 56.8%\n",
      "Memory usage of dataframe is 0.01 MB\n",
      "Memory usage after optimization is: 0.005 MB\n",
      "Decreased by 58.8%\n",
      "Memory usage of dataframe is 0.01 MB\n",
      "Memory usage after optimization is: 0.005 MB\n",
      "Decreased by 58.1%\n",
      "Memory usage of dataframe is 0.01 MB\n",
      "Memory usage after optimization is: 0.005 MB\n",
      "Decreased by 58.8%\n",
      "Memory usage of dataframe is 0.00 MB\n",
      "Memory usage after optimization is: 0.002 MB\n",
      "Decreased by 33.9%\n",
      "Memory usage of dataframe is 0.00 MB\n",
      "Memory usage after optimization is: 0.002 MB\n",
      "Decreased by 37.1%\n",
      "Memory usage of dataframe is 0.00 MB\n",
      "Memory usage after optimization is: 0.002 MB\n",
      "Decreased by 33.3%\n",
      "Memory usage of dataframe is 0.00 MB\n",
      "Memory usage after optimization is: 0.000 MB\n",
      "Decreased by 36.0%\n",
      "Memory usage of dataframe is 0.00 MB\n",
      "Memory usage after optimization is: 0.000 MB\n",
      "Decreased by 36.0%\n",
      "Memory usage of dataframe is 0.00 MB\n",
      "Memory usage after optimization is: 0.000 MB\n",
      "Decreased by 0.0%\n",
      "Memory usage of dataframe is 0.00 MB\n",
      "Memory usage after optimization is: 0.002 MB\n",
      "Decreased by 47.5%\n",
      "Memory usage of dataframe is 0.01 MB\n",
      "Memory usage after optimization is: 0.003 MB\n",
      "Decreased by 49.8%\n",
      "Memory usage of dataframe is 0.01 MB\n",
      "Memory usage after optimization is: 0.003 MB\n",
      "Decreased by 52.6%\n",
      "Memory usage of dataframe is 0.01 MB\n",
      "Memory usage after optimization is: 0.003 MB\n",
      "Decreased by 51.0%\n",
      "Memory usage of dataframe is 0.01 MB\n",
      "Memory usage after optimization is: 0.003 MB\n",
      "Decreased by 49.2%\n",
      "Memory usage of dataframe is 0.01 MB\n",
      "Memory usage after optimization is: 0.003 MB\n",
      "Decreased by 49.8%\n",
      "Memory usage of dataframe is 0.00 MB\n",
      "Memory usage after optimization is: 0.000 MB\n",
      "Decreased by 56.7%\n",
      "Memory usage of dataframe is 0.00 MB\n",
      "Memory usage after optimization is: 0.003 MB\n",
      "Decreased by 14.2%\n",
      "Memory usage of dataframe is 0.00 MB\n",
      "Memory usage after optimization is: 0.000 MB\n",
      "Decreased by 36.0%\n",
      "Memory usage of dataframe is 0.00 MB\n",
      "Memory usage after optimization is: 0.000 MB\n",
      "Decreased by 51.0%\n",
      "Memory usage of dataframe is 0.00 MB\n",
      "Memory usage after optimization is: 0.000 MB\n",
      "Decreased by 55.9%\n",
      "Memory usage of dataframe is 0.00 MB\n",
      "Memory usage after optimization is: 0.001 MB\n",
      "Decreased by 19.8%\n",
      "Memory usage of dataframe is 0.00 MB\n",
      "Memory usage after optimization is: 0.001 MB\n",
      "Decreased by 49.2%\n",
      "Memory usage of dataframe is 0.00 MB\n",
      "Memory usage after optimization is: 0.001 MB\n",
      "Decreased by 49.8%\n",
      "Memory usage of dataframe is 0.00 MB\n",
      "Memory usage after optimization is: 0.001 MB\n",
      "Decreased by 49.2%\n",
      "Memory usage of dataframe is 0.00 MB\n",
      "Memory usage after optimization is: 0.001 MB\n",
      "Decreased by 49.8%\n",
      "Memory usage of dataframe is 0.00 MB\n",
      "Memory usage after optimization is: 0.001 MB\n",
      "Decreased by 49.2%\n",
      "Memory usage of dataframe is 0.00 MB\n",
      "Memory usage after optimization is: 0.001 MB\n",
      "Decreased by 47.9%\n",
      "Memory usage of dataframe is 0.00 MB\n",
      "Memory usage after optimization is: 0.001 MB\n",
      "Decreased by 49.2%\n",
      "Memory usage of dataframe is 0.00 MB\n",
      "Memory usage after optimization is: 0.001 MB\n",
      "Decreased by 49.8%\n",
      "Memory usage of dataframe is 0.00 MB\n",
      "Memory usage after optimization is: 0.001 MB\n",
      "Decreased by 47.9%\n",
      "Memory usage of dataframe is 0.00 MB\n",
      "Memory usage after optimization is: 0.001 MB\n",
      "Decreased by 49.2%\n",
      "Memory usage of dataframe is 0.00 MB\n",
      "Memory usage after optimization is: 0.001 MB\n",
      "Decreased by 49.2%\n",
      "Memory usage of dataframe is 0.00 MB\n",
      "Memory usage after optimization is: 0.001 MB\n",
      "Decreased by 47.9%\n",
      "Memory usage of dataframe is 0.00 MB\n",
      "Memory usage after optimization is: 0.000 MB\n",
      "Decreased by 32.9%\n"
     ]
    }
   ],
   "source": [
    "data_store_train = {\n",
    "    \"df_base\": read_file(\"train_base.parquet\"),\n",
    "    \"depth_0\": [\n",
    "        read_file(\"train_static_cb_0.parquet\"),\n",
    "        read_files(\"train_static_0_*.parquet\"),\n",
    "    ],\n",
    "    \"depth_1\": [\n",
    "        read_files(\"train_applprev_1_*.parquet\", 1),\n",
    "        read_file(\"train_tax_registry_a_1.parquet\", 1),\n",
    "        read_file(\"train_tax_registry_b_1.parquet\", 1),\n",
    "        read_file(\"train_tax_registry_c_1.parquet\", 1),\n",
    "        read_file(\"train_credit_bureau_b_1.parquet\", 1),\n",
    "        read_files(\"train_credit_bureau_a_1_*.parquet\", 1),\n",
    "        read_file(\"train_other_1.parquet\", 1),\n",
    "        read_file(\"train_person_1.parquet\", 1),\n",
    "        read_file(\"train_deposit_1.parquet\", 1),\n",
    "        read_file(\"train_debitcard_1.parquet\", 1),\n",
    "    ],\n",
    "    \"depth_2\": [\n",
    "        read_file(\"train_credit_bureau_b_2.parquet\", 2),\n",
    "        read_file('train_person_2.parquet', 2),\n",
    "        read_files('train_credit_bureau_a_2_*.parquet', 2),\n",
    "        read_file('train_applprev_2.parquet', 2)\n",
    "    ]\n",
    "}\n",
    "\n",
    "data_store_test = {\n",
    "    \"df_base\": read_file(\"test_base.parquet\"),\n",
    "    \"depth_0\": [\n",
    "        read_file(\"test_static_cb_0.parquet\"),\n",
    "        read_files(\"test_static_0_*.parquet\"),\n",
    "    ],\n",
    "    \"depth_1\": [\n",
    "        read_files(\"test_applprev_1_*.parquet\", 1),\n",
    "        read_file(\"test_tax_registry_a_1.parquet\", 1),\n",
    "        read_file(\"test_tax_registry_b_1.parquet\", 1),\n",
    "        read_file(\"test_tax_registry_c_1.parquet\", 1),\n",
    "        read_file(\"test_credit_bureau_b_1.parquet\", 1),\n",
    "        read_files(\"test_credit_bureau_a_1_*.parquet\", 1),\n",
    "        read_file(\"test_other_1.parquet\", 1),\n",
    "        read_file(\"test_person_1.parquet\", 1),\n",
    "        read_file(\"test_deposit_1.parquet\", 1),\n",
    "        read_file(\"test_debitcard_1.parquet\", 1),\n",
    "    ],\n",
    "    \"depth_2\": [\n",
    "        read_file(\"test_credit_bureau_b_2.parquet\", 2),\n",
    "        read_file('test_person_2.parquet', 2),\n",
    "        read_files('test_credit_bureau_a_2_*.parquet', 2),\n",
    "        read_file('test_applprev_2.parquet', 2)\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape:\t (1526659, 487)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1635"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = feature_eng(**data_store_train)\n",
    "print(\"train data shape:\\t\", df_train.shape)\n",
    "del data_store_train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data shape:\t (10, 486)\n"
     ]
    }
   ],
   "source": [
    "df_test = feature_eng(**data_store_test)\n",
    "print(\"test data shape:\\t\", df_test.shape)\n",
    "del data_store_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape:\t (1526659, 403)\n",
      "test data shape:\t (10, 402)\n"
     ]
    }
   ],
   "source": [
    "df_train = df_train.pipe(Data_Pipeline.col_filter)\n",
    "df_test = df_test.select([col for col in df_train.columns if col != \"target\"])\n",
    "\n",
    "print(\"train data shape:\\t\", df_train.shape)\n",
    "print(\"test data shape:\\t\", df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, cat_cols = to_pandas(df_train)\n",
    "df_test, cat_cols = to_pandas(df_test, cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
